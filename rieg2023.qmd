---
title: "Socioeconomic Disruption by Artificial Intelligence"
subtitle: "A comparative analysis on labor  between industries in the European Union"
bibliography: references.bib
csl: elsevier-harvard.csl
engine: jupyter
lang: en
execute:
  echo: false
  freeze: false
  cache: false
keep-tex: true
format:
  pdf:
    include-in-header: 
      text: |
        \let\oldsection\section
        \renewcommand\section{\clearpage\oldsection}
        \usepackage[font=it,labelfont=bf]{caption}
    fig-cap-location: bottom
    tbl-cap-location: top
    papersize: a4paper
    documentclass: article
    toc: false
    link-citations: true
    number-sections: true
    colorlinks: true
    linestretch: 1.5
    lang: en
    mainfont: "Arial"
    fontsize: "11"
    geometry:
      - top=25mm
      - left=25mm
      - right=25mm
      - bottom=20mm
      - heightrounded
---

```{=latex}
\pagenumbering{Roman}
```
{{< pagebreak >}}

```{=latex}
\tableofcontents
```
{{< pagebreak >}}

```{=latex}
\listoffigures
```
{{< pagebreak >}}

```{=latex}
\listoftables
```
{{< pagebreak >}}

```{=latex}
\pagenumbering{arabic}
```
# Abstract

# Introduction {#sec-introduction}

```{python}
#| label: setup

import yaml
import pandas as pd
from IPython.display import Markdown, HTML, Latex, display, Image
import json
import importlib
import source.transform as tf
importlib.reload(tf)
import source.utils as ut
import source.extract as ex
import source.statsvis as sv
importlib.reload(sv)
import plotly.express as px
import json
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np

with open("source/config.yaml", "r") as f:
  config = f.read()
config = yaml.safe_load(config)

```

```{python}
#| label: prep-dataframes

eurostat = tf.prep_eurostat_data(data_path=config["paths"]["eurostat_sbs_data"], 
                                 indic_sb_codes=config["paths"]["eurostat_indic_sb_codes"],
                                 nace_codes=config["paths"]["eurostat_nace_codes"])
#TODO: insert path from config
with open("data/retrieved_data/biblio-search_EP.json") as f:
    patent_data = json.load(f)
# extract patent data
patents = tf.tf_search_biblio(ex.extract_biblio(patent_data))
prepped_patents = tf.prep_patents(patents)
prepped_df_raw = tf.prep_data(prepped_patents_df=prepped_patents, prepped_eurostat_df=eurostat, time_all=False, detrended=False)
prepped_df = tf.prep_data(prepped_patents_df=prepped_patents, prepped_eurostat_df=eurostat, time_all=False, detrended=True)
INDUSTRIES = prepped_df["NACE"].unique()
INDICATORS = prepped_df["Indicator"].unique()
```

```{python}
descriptives = sv.descriptives(prepped_df_raw)
descriptives_d = sv.descriptives(prepped_df)
```

@mokyr_history_2015 [p. 32] identifies two forms of technological anxiety, the fear of labor displacement through technology and and the fear of morally negative applications resulting in declining welfare. The majority of the US population has been found to assess the potential impact of automation as unfavorable rather than beneficial [@anderson_automation_2017].

Since AI is a still fairly new topic in the literature and has only seen real increase in dominance and interest in recent years [@acemoglu_ai_2020, p. 23f.], is is worth noting the effects of previous technologies as the adoption of machines (specifically often industrial robots [see for example @graetz_robots_2015; @acemoglu_robots_2020]) and software (also referred to as computerization[see for example @pajarinen_computerization_2015; @frey_future_2017; @autor_growth_2013]) have been seen as previous stages in the evolution of automation with AI composing the next stage [@acemoglu_harms_2021, p. 19]. Furthermore, these technologies have been summarized under the umbrella term "automation" [@mann_benign_2018, p. 40] indicating common characteristics and thereby - possibly - common effects.

## Effects of Automation on labor {#sec-effects-of-automation-on-labor}

In a 2018 study, the introduction of automation technology was found to have positive effects on employment gains, but only within the same commuting zone [@mann_benign_2018, p. 26]. These findings contradict the results from @autor_untangling_2015 \[p. 632\], that found no relation between exposure to automation and employment as a whole but found a significant decline in employment related to routine tasks in the non-manufacturing sector (p. 641). @graetz_robots_2015 [p. 766] found no relationship between the usage of industrial robots and net employment. However, usage of industrial robots was found to lower employment of low-skilled workers. However, a later study also looking at employment effects induced by usage of industrial robots found a significant decline of employment as well as a reduction in wages related to robot exposure within a commuting zone [@acemoglu_robots_2020, p. 2215f, 2218]. @dauth_german_2017 \[p. 25\] found no relation between robot exposure and employment in the German market. A few years later, @dauth_adjustment_2021 [p. 3126ff] found robot exposure to lead to within-firm and between-firm job displacement, with displaced workers having difficulties reallocating their jobs within the same industry, leading to a migration of workers from manufacturing (where robot exposure is most present) to the service sector. They also exhibited that a lack of worker protections (for example unionization or tenure) is related to greater displacement. These results were also confirmed by @boustan_automation_2022 \[p. 21, 23\] who observed that displaced workers acquire new skills and concluded job displacement by automation to be less discernible amongst unionized and high-skilled workers. Similarily, @acemoglu_robots_2020 [p. 2215f., 2218] provided evidence showing automation (adoption of industrial robots) within a commuting zone (local labor market) relating to significant declines in employment as well as wages. By studying 53 developing countries, @cirera_effects_2019 [p. 172] did not find a relationship between exposure to automation and firm level employment. Hoewever, while a net effect on employment was absent, in line with the aforementioned literature, they did find automation to alter the composition of tasks and skills within firms (p. 172).

In a purely theoretical approach to the effects of automation on labor, @acemoglu_low-skill_2017 \[p. 12, 15\] concluded that automation leads to labor displacement and the displacement of low skilled-labor leading to an increase in the wage gap (pay gap between low-skilled and high-skilled workers) while the displacement of high-skilled labor is followed by a reduction in the wage gap as high-skill labor reallocates into medium- and low-skilled occupations. This reallocation from displaced high-skill labor into lower skilled occupations has also been shown by @beaudry_great_2016 [p. 21] who studied the effects on labor when prices for specific types of labor fall - as is induced when substitution (through technology) becomes economically viable. While labor displacement induced by the introduction of automation is followed by increased inequality between low-skill and high-skilled labor in the short run [@acemoglu_race_2018, p. 1519], the creation of new tasks - that is followed by increased productivity gains from automation - is seen to reduce this gap in the long run (p. 1521). However, this positive outlook of a net positive on employment only holds true as long as the productivity effects which accompany the adoption of automation technologies offset the displacement effects incurred in the first place - and should the offset be insufficient, automation is found to negatively impact the demand for labor and its wages [@acemoglu_artificial_2018, p. 227]. There is also growing evidence suggesting automation to cause a decline in real wages of low-skilled workers, for example @acemoglu_unpacking_2020 \[p. 360f.\] found strong relationships between the adoption of automation technology and wages. @acemoglu_tasks_2022 [p. 1993] found a relationship between labor displacement and a decrease in relative wages, concluding automation to cause an increase in wage inequality (p. 1998). Automation is also attributed to the decline in the demand for labor in the US over recent decades [@acemoglu_automation_2019, p. 21].

Furthermore, @arntz_risk_2016 \[p. 14f.\] studying 21 OECD countries found 9% in the US, and over all countries studies a 6-12% high risk of employment to be substitutable for automation, while @acemoglu_chapter_2011 [p. 61] came to the conclusion that labor displacement by machines mostly affects routine tasks.

## Effects of computerization {#sec-effects-of-computerization}

In a study from Finland, @pajarinen_computerization_2015 found that computerization is likely to place high risk of displacement on 35% of the Finish labor market [p. 5], 33% of Norwegian labor (p. 5) as well as 49% in the US [p. 5]. @frey_future_2017 [p. 41] found 47% of US employment to have a a high risk suitability for substitution by computerization. They further classify the process of automation into two "waves" with the first wave affecting routine tasks (transportation, logistics, office, and administration) \[p. 41\] followed by a second wave that, once technological obstacles are overcome, will effect the jobs involving creative or abstract tasks \[p. 43\]. Evidence also suggests computerization to significantly induce labor displacement from occupations relying on routine tasks into higher-skilled occupations as well as low-skilled service occupations [@autor_growth_2013, p. 1573]

## Effects of AI {#sec-effects-of-ai}

@brynjolfsson_what_2018 \[p. 46\] found that machine learning affects different types of tasks than earlier forms of automation. A year later, in a study comparing the impact of AI on the job market between industries, @webb_impact_2019 [p. 46] shows that AI affects mostly the highly educated workforce and that this group is affected significantly more by AI than the presence of software or robots. Under the assumption that the current trend in technological evolution is set to continue, the speed of labor displacement through technological innovation is found likely to outpace the speed at which labor can be relocated [@mokyr_history_2015, p. 43f.]. By constructing impact scores of Artificial Intelligence on occupations, @felten_effect_2019 found low-income occupations to experience a decline in wage growth that is attributed to the increased presence of AI and middle and high-income occupations to experience an increase in wage growth \[p. 6\]. Furthermore, the authors found found that occupations with a medium and high degree of automation (degree of automation being the presence of automation technologies - not just AI) positively correlate with employment when exposed to Artificial Intelligence, while they did not find any relationship for occupations already exhibiting a low degree of automation \[p. 5\].

It has also been noted that the presence of Artificial Intelligence does not have a linear impact on labor but depends on influencing factors, such as price elasticity, complementarities, or elasticity of labor that govern the implementation of these technologies [@brynjolfsson_what_2017, p. 1533f.]. Additionally, the adoption of AI technology is found to significantly alter the skill-demand distribution of firms, with the number of previously highly demanded skills declining while simultaneously creating demand for new skills [@acemoglu_ai_2020, p. 19].

## Changes of Occupational composition {#sec-changes-of-occupational-composition}

Furthermore, it is important to note that previous research on the effects of robots, software and AI - that have been summarized under the umbrella term "automation" [@mann_benign_2018, p. 40] - in general may not have found net negative effects on employment but a restructuring of composition of occupations. The aforementioned study from @autor_untangling_2015 \[p. 644\] found automation, while having no aggregate effects on employment, lead to a decline in occupations involving routine tasks and and an increase in non-routine (abstract) tasks. The same effect was found in @graetz_robots_2015 [p. 766] studying the introduction of industrial robots. These effects remain only harmless as long as the assumption holds true that displaced labor can in fact always reallocate itself to new tasks. Should this assumption be contradicted, and the the negative effects of automation on employment are no longer offset by the positive effects of reallocation, the phenomenon of occupational migration would turn into an observation of job destruction.

## Changes in labor share

The introduction of capital, whether to complement or substitute labor, intuitively leads to a decline of a firms profits paid to labor as the share of labors input relative to the output value decreases. And in fact @karabarbounis_global_2014 \[p. 99\] show that the observed decline in capital prices explains almost half the decline in global labor share, that has been observed in recent decades. This might seem problematic as an increasing portion of a firms revenue remains as corporate profits and savings (given that the capital invested leads to a decrease in marginal costs - through substitution of labor and/ or increased production) rather than being redistributed to labor. @karabarbounis_global_2014 [p. 102] further show that the observed decline in labor share is accompanied by an increase in corporate revenue and savings. This is also brought forward from @acemoglu_automation_2019 \[p. 27\] who conclude that "\[...\] automation always reduces the labor share and may reduce labor demand \[...\]" but also mention that the creation of new tasks necessarily increases the labor share. These results where further solidified by @acemoglu_competing_2020 [p. 387] who investigated the French manufacturing market and found firms exposed to automation (in this study measured by the introduction of robots) to experience significant declines in their labor share.

## Summary of the different findings -\> why findings differ

The net impact assessment of automation on socioeconomic factors widely differs in the aforementioned literature [see also @frank_toward_2019, p. 6532]. Some research has focused on local labor markets (commuting zones) [see @acemoglu_robots_2020; @autor_untangling_2015; @autor_growth_2013], while other research has researched national effects [see xxx] and international effects [see @graetz_robots_2018]. While one would expect to see the same relationship between the chosen variables on all levels and apart from differences in research design, it may be difficult to assess effects on a greater aggregate level as the number of variables that would need to be included to account for differences between and within groups becomes unfeasible.

## Definitions of AI

The classification if Artificial Intelligence remains also difficult due to the fact that there is yet no widespread agreement on the definition of intelligence itself [@legg_collection_2007].

Given the various contradicting results on the relationship between automation and labor effects and the increasing presence of AI, this research aims to add to the current corpus of literature by assessing the relationship between AI innovation and socioeconomic factors. Specifically, the research question is as follows: How does AI innovation across industries impact labor?

#TODO: define that AI and machine learning are sometimes regarded as two different things. But that this paper uses the two interchangeably. (Crawford)

# Methodology

The methodological approach has similarities to @mann_benign_2018 [p.13] who used patent counts as a proxy for estimating the level of automation present within a US commuting zone. However, the method of selecting patents differs. While @mann_benign_2018 classified texts based on the tasks they may effect within occupations, the presented approach here uses API query composition to preselect patents whose title or abstract match keywords reserved to an industry.

## Data Sources {#sec-data-sources}

Data about patent publications is obtained from the European Patent Office's Open Patent Services (OPS) API [@european_patent_office_open_2023] as well as the Annual Structural Business Statistics (SBS) by Eurostat [@eurostat_annual_2023]. Furthermore, Eurostats code lists of Statistical classification of economic activities in the European Community (NACE Revision 2) [@eurostat_statistical_2023] (henceforth "NACE") and economic indicators for Eurostat's SBS [@eurostat_economical_2023] are retrieved to map codes to their respective definition. Additionally Cooperative Patent Classification (CPC) codes are retrieved manually from the European Patent Ofiice's Espacenet website [@classifi].

### OPS API

The European Patent Office's OPS API allows for programmatic access to the Patent Office's database [@openpat2023]. With it, one can retrieve data on individual patents, such as -amongst others- their title and abstract, date of application, place of application, the names of the applicants, the patents classification (CPC), and a patent's references to other patents and documents.

While there are a variety of possible technologies that may fall under the umbrella term "Artificial Intelligence", as this research aims to assess AI's socioeconomic impact - which, if negative, falls into the governmental realm - a legal definition of AI is preferable as a classifier. Furthermore, it is arguable that the political definition is likely to have the greatest (socio)economic impact in the near future due to possible (and probable) regulation. As there is no legal definition yet - at least in the EU - technologies listed in the European Commisions latest proposal for the "Artificial Intelligence Act\['s\]" [@european_commission_proposal_2021] annex [@european_commission_annexes_202] will be used.[^1]

[^1]: The European Commission's proposal for the "Artificial Intelligence Act" is currently in the legislative process. At the time of writing, the European Parliament has made amendments to this proposal, one of which - unfortunately - is the removal of the list of technologies classified as AI from the initial proposal's annex [@p9ta(202023, p. 326f.]. For the time being, the AI Act now lacks a clear defintion which is why the European Comission's initial proposal's definition will be used.

Additionally Cooperative Patent Classification (CPC) codes are used to retrieve patents that utilize artificial intelligence technology. As there is no clear mapping between the European Commission's definition and CPC codes, classifications are chosen to the author's best knowledge.

\setstretch{1}

```{python}
#| label: tbl-cpc-codes
#| tbl-cap: Selected CPC Codes
#| tbl-pos: H

# show cpc codes as table
cpc = dict()
for key in config["CPC"].keys():
  cpc[key] = ", ".join(config["CPC"][key])
cpc = pd.DataFrame.from_dict(cpc, orient="index", columns=["CPC"]).reset_index().rename(columns={"index": "Class"})

Markdown(cpc.to_markdown(index=False))
```

\setstretch{1.5}

### Why certain variables have been chosen? -\>

## Data Acquisition {#sec-data-acquisition}

In order to retrieve data from the European Patent Office's Open Patent Services (OPS) API, queries were composed to link retrieved patents to their respective industry. The query composition is based on the selected CPC codes displayed in @tbl-cpc-codes as well as keywords from the list of NACE codes that have been retrieved from Eurostat. Each NACE code is composed of section (alphabetical), division (numerical), group (numerical) and class (numerical) of a particular economic activity. Sections relate to the overall industry, while divisions, groups and classes relate to more specific activities within the industry [@nacebac]. For each industry, keywords are extracted from the NACE code's description. To ensure only relevant keywords are used, each description is cleaned of common characters and unrelated words (e.g., ",", "and", "or", "to"). Descriptions for each industry are then split into lists of single keywords that will be used in the API query.

Because some industries contain a variety of different activities (e.g., NACE industry (section) "A" relates to "Agriculture, forestry and fishing" [@eurostat_economical_2023]), main keywords that relate to the section as a whole are manually selected (see @tbl-nacemainkeywords in the \nameref{sec-appendix}). For each industry and main keyword, queries are then build using the (manuallly selected) main keyword, the description keywords, as well as the chosen CPC codes. The resulting query is then used to retrieve patents from the OPS API. Initially, queries were created not only for the European Patent Office but all patent offices within the European Union to retrieve patent data on a national level. This approach would have resulted in a much richer dataset, enabled better aggregates while also allowing for between-country comparissons. However, initial tests showed that most of the patents filed with a national patent office contain only patent titles and absracts in their native language which renders the chosen keywords in the query language (English) ineffective. As a result, the decision was made to only retrieve patents filed with the European Patent Office. This approach disregards patents filed with national patent offices. The query is composed of the following elements:

\setstretch{1.0}

> **(ta = Main Keyword) AND (ta = ANY Description Keywords) AND (cpc ANY CPC Codes) AND (ap = "EP")**\
> *Note: ta = title or abstract; ap = Application Number, referring to the Patent Office the patent was filed at. In this case, "EP" refers to the European Patent Office. See @tbl-queryexample for example queries*

\setstretch{1.5}

The queries are then posted to the OPS API's Published Data Keywords Search with Variable Constituents endpoint [@european_patent_office_published_nodate] and data from the responses - which are provided in JSON format - extracted.

## Preprocessing {#sec-preprocessing}

Since Eurostat's SBS data only includes codes to refer to given indicators as well as industries, data retrieved from Eurostat (SBS, and Code Lists about NACE and SBS codes) is merged. This is done by matching the NACE codes and SBS indicator codes to the respective NACE code and indicator in the SBS data. The economic indicators "Enterprises" and "Persons employed" are reported as totals. "Wage adjusted labour productivity (Apparent labour productivity by average personnel costs)" and "Share of personnel costs in production" are reported as percentages, and "Gross value added per employee" is reported in Euros. Because the number of employees is rather large for each industry, the number of employees is divided by 1000 to reduce the scale of the data. This increases readability of tables in the following regression results while also still large enough that it is unlikely for coefficients (coeff.) and standard errors (SE) to fall too far into the decimals.[^2]

[^2]: Note that this is done to ensure readability and does not affect the regression results. Defactoring data by more than a thousand might lead to coefficients and standard errors falling into the decimals, which in turn may show up - due to rounding - as zeros despite having large scale effects (when rescaled with the original factor).\label{note3}

Next, patent data retrieved from the OPS API, which returns data in JSON format, is converted into a pandas DataFrame [@the_pandas_development_team_pandas-devpandas_2023] (i.e., a table). As multiple queries for the same industry - but with different keywords - have been posted to the API, duplicates in the patent data are removed. Specifically, duplicate patent data (indicated by the patent application number) are removed in each industry subset of the data. This ensures that each industry only contains unique patents while patents can still appear in more than one industry (as their applicable usage may not be restricted to only one industry). Furthermore, as the SBS data only spans from 2011 to 2020, patents that have been filed before or after this period are removed from the data. As a next step, patents are grouped by their respective industry and year of application and the patent count for each subgroup is recorded. Furthermore, industries for which patents have been retrieved in less than four years within 2011-2020 are removed from the data to ensure a minimum sample size for the following statistics. The sum of patents for each industry and year composes the exogenous variable "Sum patents" that will be used in the regression analyses.

Furthermore, the SBS data is merged with the patent data by matching the industry and year of application with the industry and year of the SBS data. This ensures that each industry and year combination in the SBS data has a corresponding patent count. Furthermore, the data is once more grouped for each industry to retrieve the earliest and latest year for which patent counts are available. For each industry, SBS data is removed for the years before and after the first and last patent retrieval for the respective industry. This is done to ensure that the regression analyses are only conducted for years in which patent counts are available.[^3] However, in some cases, patents were discontinuously retrieved for industries. In other words, if patents are retrieved for an industry in 2016, 2018, 2019, and 2020, but not in 2017, the SBS data for 2017 and the respective do not have a corresponding patent count. In order to account for missing values within a series of definite patent retrieval, the patent count for the missing year is set to zero. This is done for each industry and year combination in which patent counts are missing.\label{cleaning-missing-values}

[^3]: There are valid arguments to be made for and against excluding these data. For once, the lack of patent retrieval for any given year implies no patent filing within that year, making null values a good control instance to check for variation in SBS data that is definitely not affected by patent filings. On the other hand, for a few industries, this would result in many null values, giving the data series of patent counts a definite trend. Furthermore, patent counts have also been removed for years in which SBS data is unavailable. To reduce potential bias produced by imputing and keeping the data's integrity, removing the missing values has been chosen over the data's accuracy.

Lastly, in some rare cases, SBS data is missing for a given year and industry. In these cases, rows of the respective year and industry are removed from the data. This is done to ensure that the regression analyses are only conducted for years in which SBS data is available. The resulting data is then used for the regression analyses. In summary, data for each year and industry will be used further if the following conditions are met.

1.  Patents have been retrieved for the industry in at least four years within 2011-2020
2.  Patents have been retrieved for this or an earlier year
3.  Patents have been retrieved for this or a later year
4.  SBS data is available for this year and industry

The resulting data contains `{python} descriptives["len_df"]` data points across `{python} descriptives["num_industries"]` Industries, each with `{python} descriptives["num_indicators"]` economic indicators. However, given the relatively short time period in which data could have been collected, paired with the fact that the retrieved patents are aggregated for each year, the resulting data size for each industry and economic indicator is relative small. The average number of years in which patent counts have been recorded -according to the methods above- is only `{python} descriptives["average_years"]` years, ranging from a minimum of `{python} descriptives["min_years"]` years up to `{python} descriptives["max_years"]` years. Since each year per industry and indicator will be used as a data point in the following regression analyses, it is neccesary to note that results may be biased due to the small sample size. Furthermore, given the small dataset -which makes diminishes the accuracy with which a regression can be fitted (i.e., fewer "anchor points"), assumptions about the extend to which patent counts affect the chosen economic indicators will not be made. Instead, the regression analyses will be used to assess whether a relationship between the number of patents and the chosen economic indicators exists at all. That is, the interest lies whether AI patent counts yield any explanatory power over the chosen economic indicators.

Because the collected data comrpises a time-series, as each industry's patent application counts as well as the SBS data have been retrieved for multiple years. As shown in @fig-untransformed-data-example, the collected data on SBS indicators (blue) as well as the number of patents retrieved each year (red) clearly does not exhibit stationarity. In order to account for any trends in the data, the collected data is transformed using linear detrending method. This is done by utilicing scipy's detrending method [@virtanen_scipy_2020], which fits a linear least-squares regression to the data and subtracts the resulting trend of the regression line from the data [@the_scipy_community_scipysignaldetrend_2023]. Note that other detrending options, such as logarithmic transformation or differencing have been considered but deemed insifficient. Logarithmic transformation is not applicable as the data contains zero values. While there are methods to circumvent this, for example taking the logarithm $log(x+1)$, this would lead to non-null values where null values are expected to control for variance in the endogenous variable in the absence of patent counts. Furthermore, as seen in @fig-untransformed-data-example, many data series exhibit a continues positive or negative trend (a lack of fluctuation). In this case, differencing would merely reverse the trend, and logarithmic detrending would lead to a compression of the y-scale. Resulting data transformed by either of these methods, however, would still exhibit a definite trend. The resulting data, of which an example is shown in @fig-transformed-data-example, is then used for the regression analyses.

```{python}
#| label: fig-untransformed-data-example
#| fig-cap: "Example of untransformed data for all Industries and NACE Code 'Number of Employees' plotted over years"
#| fig-pos: H

tmp_df = prepped_df_raw[prepped_df_raw["Indicator"] == "Employees (n)"]
fig = sv.subplots_two_yaxes(df = tmp_df, x="Year", x_name="Year", y1="OBS_VALUE", y1_name="Employees (n)", y2="Sum patents", y2_name="Sum patents", by="Industry", rows=3, cols=2)
fig.update_layout(
    margin=dict(l=0, r=0, t=15, b=0),
)

Image(fig.to_image(format="jpeg", engine="kaleido", scale=3, height=500, width=800))
```

```{python}
#| label: fig-transformed-data-example
#| fig-cap: "Example of linear detrended data for all Industries and NACE Code 'Number of Employees' plotted over years"
#| fig-pos: H

tmp_df = prepped_df[prepped_df["Indicator"] == "Employees (n)"]
fig = sv.subplots_two_yaxes(df = tmp_df, x="Year", x_name="Year", y1="OBS_VALUE", y1_name="Employees (n)", y2="Sum patents", y2_name="Sum patents", by="Industry", rows=3, cols=2)
fig.update_layout(
    margin=dict(l=0, r=0, t=15, b=0),
)


Image(fig.to_image(format="jpeg", engine="kaleido", scale=3,height=500, width=800))
```

Because data has been linearily detrended, to account for any remaining trend left in the data, the control variable "Year" is added to the regression analyses. This is done to ensure that any remaining trend in the data is accounted for and does not bias the regression results. Furthermore, the control variable "Year" is also added to the regression analyses to account for any time dependent macroeconomic effects that may have affected the chosen economic indicators but are not considered in the model.

## Model {#sec-model}

#TODO: State research question again #TODO: Why linear regression was chosen?

### Hypothesis {#sec-hypothesis}

Do determine whether a relationship between the number of patents and the chosen economic indicators exists, the following hypotheses are tested. Given a standard multiple linear regression model of the form $y_{i,j} = \beta_0 + \beta_1x_i + \beta_2x_t$, where $i=\text{industry, }j=\text{economic indicator }\text{and }t=\text{time}$, the coefficient $\beta_1$ is assumed to be $0$. Specifically, the following assumptions are tested.

```{=tex}
\begin{align}
H_{0, i, j}: \beta_1 = 0\text{ for }j=e=\text{number of enterprises} \\
H_{0, i, j}: \beta_1 = 0\text{ for }j=L=\text{number of employees} \\
H_{0, i, j}: \beta_1 = 0\text{ for }j=l=\text{wage adjusted labor productivity} \\
H_{0, i, j}: \beta_1 = 0\text{ for }j=v=\text{gross value added per employee} \\
H_{0, i, j}: \beta_1 = 0\text{ for }j=c=\text{personnel costs in production}
\end{align}
```
# Results {#sec-results}

The following section presents the main findings from the regression analyses. Results are summarized by industry, allowing a sectional comparrison of patent counts' influence on economic indicators within an industry.

```{python}
#| label: regression

results = sv.run_regressions(data=prepped_df, industries=INDUSTRIES, indicators=INDICATORS, x_cols=["Sum patents", "Year"], successive=False)
results_by_industry = sv.summarize_results(results=results, indicators=INDICATORS, industries=INDUSTRIES, by="industry")
results_by_indicator = sv.summarize_results(results=results, indicators=INDICATORS, industries=INDUSTRIES, by="indicator")
```

\setstretch{1}

```{python}
#| label: tbl-regression-results-ind-b
#| tbl-cap: "Regression results - Mining and Quarrying (B)"
#| tbl-pos: H

# show regression results as table
display(Markdown(results_by_industry["B"].tables[0].to_markdown(index=True)), 
# Latex(r"\rule{\textwidth}{1pt}"),
Markdown("_\* p < 0.1, \*\* p < 0.05, \*\*\* p < 0.01. Standard errors in paranthesis_"))
```

\setstretch{1.5}

For patents classified as industry "Mining and Quarrying" (NACE code "B"), depicted in @tbl-regression-results-ind-b, the regression results show no significant relation between the sum of patents retrieved for each year and the chosen indicators. Furthermore, the control variable "Year", too, does not exhibit any significant relationships with the economic indicators. It should be noted, howver, that the number of patents retrieved for this industry is very low. While, as discussed in the \nameref{sec-data-acquisition}, industries for which patents were retrieved in fewer than five years were eliminated from the data, for Mining and Quarrying only `{python} descriptives["B_n_patents"]` patents in `{python} descriptives["B_n_years"]` years were retrieved. As a result, the nullhypotheses $H_{0, i, j}\text{ for }j\in \{e, L, l, v, c\}, i=B$ are not rejected.

\setstretch{1}

```{python}
#| label: tbl-regression-results-ind-c
#| tbl-cap: "Regression results - Manufacturing (C)"
#| tbl-pos: H

# show regression results as table
Markdown(results_by_industry["C"].tables[0].to_markdown(index=True))
```

\setstretch{1.5}

For patents classified as industry "Manufacturing" (NACE code "C"), depicted in @tbl-regression-results-ind-c, the regression results show a statistically significant negative relationship between the number of retrieved patents and the number of employees within the Manufacturing sector (coeff. -82.488.8, SE 18.243\`). In particular, the regression result's coefficient estimates a decrease of 82489 employees for each additional patent retrieved[^4]. Furthermore, the control variable "Year" does not exhibit a statistically significant relationship with the number of employees (coeff. 0). The adjusted $R^2$ of 0.82 indicates a high ratio of explainability for the model.

[^4]: Note that while the coefficient's implications are mentioned, this merely refers to the slope of the regression line and should not be interpreted as valid result with real-world implications. The regression model is not intended to be used for prediction.

While there are no statistically significant relations between the number of patents retrieved and the number of enterprises, wage adjusted labor productivity (labor prod.) and the percentage of personnel costs in production, the relationship between the number of patents and the gross value added per employee is statistically significant and negative (coeff. -203.313, SE 34.574) with an adjustes $R^2$ of 0.89. Lastly, it should be noted that the control variable does not exhibit a statistically significant relationship with any of the economic indicators. In summary, As a result, the nullhypotheses $H_{0, i, j}\text{ for }j\in \{L, v\}, i=C$ are rejected and $H_{0, i, j}\text{ for }j\in \{e, l, c\}, i=C$ cannot be rejected.

\setstretch{1}

```{python}
#| label: tbl-regression-results-ind-d
#| tbl-cap: "Regression results - Electricity, gas, steam and air conditioning supply (D)"
#| tbl-pos: H

# show regression results as table
Markdown(results_by_industry["D"].tables[0].to_markdown(index=True))
```

```{python}
#| label: tbl-regression-results-ind-f
#| tbl-cap: "Regression results - Construction (F)"
#| tbl-pos: H

# show regression results as table
Markdown(results_by_industry["F"].tables[0].to_markdown(index=True))
```

\setstretch{1.5}

For patents classified as industry "Electricity, gas, steam and air conditioning supply" (NACE code "D"), depicted in @tbl-regression-results-ind-d, as well as for patents falling into the "Construction" ("F") industry [@tbl-regression-results-ind-f] the regression results show no statistically significant relationship between the number of patents retrieved and the chosen economic indicators. The control variable "Year", too, does not exhibit a statistically significant relationship with the chosen indicators. Furthermore, the adjusted $R^2$ is very low (and often even negative) across all dependent variables, indicating no explanatory power of the model. Therefore, the nullhypotheses $H_{0, i, j}\text{ for }j\in \{e, L, l v, c\}, i\in\{D, F\}$ cannot be rejected.

\setstretch{1}

```{python}
#| label: tbl-regression-results-ind-h
#| tbl-cap: "Regression results - Transportation and storage (H)"
#| tbl-pos: H

# show regression results as table
Markdown(results_by_industry["H"].tables[0].to_markdown(index=True))
```

\setstretch{1.5}

The regression models between number of patents allocated to the transportation and storage industry (H) and the chosen endogenous variables, depicted in @tbl-regression-results-ind-h, show a number of statistically significant relationships. First, the number of filed patents is statistically significant in predicting the number of Enterprises present in any given year. The coefficient of 94.78 (SE 159.016) implies a positive relationship between the number of AI patents and the number of Enterprises. The control variable remains statistically insignificant. This holds also true for the remaining indicators modelled within the transportation and storage industry. The adjusted $R^2$ of 0.57 indicates that over 50% of the predictors' variance is explained by the model. No statistically significant relationship can be reported between the industries retrieved annual patent counts and the number of employees and gross value added per employee. However, wage adjusted labor productivity exhibits a statistically negative relationship to increasing patent AI patent filings with a coefficient of -0.102 and a standard error of 0.029 (Adj. $R^2$ 0.532). The same relationship occurs for the percentage of personnel costs in production is found to be significantly positively related to the number of patents filed (coeff. 0.005, SE 0.005). To conclude, hypotheses $H_{0, i, j}\text{ for }j\in \{e, l, c\}, i=H$ are rejected and $H_{0, i, j}\text{ for }j\in \{L, v\}, i=H$ cannot be rejected.

\setstretch{1}

```{python}
#| label: tbl-regression-results-ind-j
#| tbl-cap: "Regression results - Information and communication (J)"
#| tbl-pos: H

# show regression results as table
Markdown(results_by_industry["J"].tables[0].to_markdown(index=True))
```

\setstretch{1.5}

Lastly, the regression models' results, as shown in @tbl-regression-results-ind-j, paint a somewhat similar picture for the information and communication industry (NACE code "J"). Here no significant relationship was found between the number of patents retrieved and the number of enterprises, with a negative adjusted $R^2$, showing independent variables yielding no explanatory power over the dependent variable. The same results can be reported for the model on the number of employees. However, the number of patents retrieved is found to be significantly and positively related to wage adjusted labor productivity (coeff. 0.033, SE 0.008) and results show an adjusted $R^2$ of 0.645. The same relationship can be reported for the gross value added per employee (coeff. 22.082, SE 3.893), which yields the highest adjusted $R^2$ (0.770) of all models in this analysis. The number of AI patents does not significantly explain the percentage share of personnel costs in production. Therefore, $H_{0, i, j}\text{ for }j\in \{l, v\}, i=J$ are rejected and $H_{0, i, j}\text{ for }j\in \{e, L, c\}, i=J$ are accepted.

In summary, the models' results paint a rather mixed picture with the majority of models tested showing statistically insignificant relationships between the number of AI patents retrieved for an industry, and the the chosen economic indicators reported within each industry. Only seven out of the 30 models tested exhibit statistically significant relationships. The results are further exacerbated, when one considers the fact that the chance of a rare event occuring increases with repeated exposure to that probability.[^5] A common method to correct for the possibility of false positives is the Bonferroni Correction [@mittelhammer_econometric_2000, p. 73f.]. Given the above chosen $\alpha$-level of 0.05, the Bonferroni Correction counterbalances the increased likelyhood of rare events (in this case, the Type I error) occuring when exposed to a plurality of situations in which they could occur (e.g., running a multitude of regressions). The Bonferroni Correction is calculated by dividing the chosen $\alpha$-level by the number of tests conducted. In this case, the Bonferroni Correction would be $\frac{0.05}{30}=0.00167$. This means that accounting for the number of models evaluated in this section, adjusted $\alpha$-level would need to be set to 0.00167 to diminish the chance of false positives in the models' results.

[^5]: A good analogy would be that the chance of winning the lottery increases with repeated playing. Or that the chance of rolling a six on a die is more likely in four rolls than in one roll.

\setstretch{1}

```{python}
#| label: tbl-pvalues
#| tbl-cap: Retrieved  significant p values for coefficients of number of patents by industry and indicator
#| tbl-pos: H
pvalues = sv.extract_pvalues(results, decimals=5, stars=False, threshold=0.05)
Markdown(pvalues.to_markdown(index=True))
```

\setstretch{1.5}

@tbl-pvalues, depicts only the number of patents' coefficient's p-values that lie beneath the unadjusted $\alpha$ threshold of 0.05. When considering the adjusted $\alpha$ value of 0.00167, one can see that merely one regression result's p value fulfills the new criterion (wage adjusted labor productivits in industry J). To conclude, the presented regression results vary in their significance and explanatory power to such extent, that is doubtful in how far relationships, while being statistically significant, actually exist. Furthermore, the Bonferroni Correction shows that the at least some of the presented results are likely to be false positives.

# Discussion {#sec-discussion}

## Implications

This research aims to answer the question of if and how AI innovation impacts labor. Given the mixed results presented in @sec-results, it is difficult to deduce clear implications of the findings. While there are significant relationships between some of the number of AI patent filed and industries and indicators, the vast majority depicts -if any- insufficiently strong links between the main predictor and predicted variable. Furthermore, as discussed in @sec-results, when adjusting the p value threshold for the number of models fitted, only one model out of 30 fits fulfills this new threshold. Furthermore, as this research utilized an in some degree novel approach to assess the relationship between AI innovation and labor, the absence of significant findings still aids to enrich the current corpus of literature by providing evidence that the relationship between AI patents filed and the chosen economic indicators is not as clear as one might expect. Nevertheless, when looking at between-industry and between-indicator results, a few interesting findings can be reported.

\setstretch{1}

```{python}
#| label: tbl-pvalues-extended
#| tbl-cap: Significant p values with coefficient sign, sample size and total number of patents
#| tbl-pos: H
pvalues_stars = sv.extract_pvalues(results, decimals=5, stars=True, threshold=0.05)
pvalues_extended = sv.extent_pvalues(pvalues = pvalues_stars, prepped_df=prepped_df_raw, sum_name="Patents (sum)", count_name="Sample size").replace(np.nan, "")
Markdown(pvalues_extended.to_markdown(index=True))
```

\setstretch{1.5}

@tbl-pvalues-extended builds upon @tbl-pvalues and depicts the significant regression results from @sec-results that fall beneath the unadjusted \alpha treshold of 005 in conjunction with the sign of the sum of patent's coefficients ("\*" for a positive coef.) as well as the number of total patents retrieved by industry and indicator ("Patents (sum)") and the sample size by industry and indicator ("Smple size"). The sum of patents here is the total sum of individual patents retrievd. The sample size denotes the number of aggregates that are contained in each group.[^6] The first corss-industry finding is that significant relationships have only been found in groups that lay in the upper half of the total number of patents retrieved. While for industries B, D, and F no statistically significant relationships were found, these industries also had the lowest number of total patents retrieved with 17, 26, and 21 respectively. The industries with the highest number of patents retrievd, C, H, and J, in turn all exhibit at least two statistically significant relationships. Furthermore, besides wage adjusted labor productivity in industry H (Transportation and storage), if effects where present in an industry, they do exhibit the same relationship within one industry. For example, in industry C (Manufacturing), the significant effects of AI patent applications on the number of employees as well as the gross value added per employee are both negative. While, as discussed in \nameref{#sec-introduction}, automation tends to always displays labor (whether on a macro or micro level), the displacement of labor, which is depicted here on an EU-wide industry level, should inuitively relate to higher marginal productivity per employee and therefore higher gross value added. However, the results show that the number of employees as well as the amount of gross value added per employee decreases with an increasing number of AI patent applications. This does suggest that the manufacturing industry is contracting with an increase number of AI patents filed.[^7] Nevertheless, it should be noted that this does not mean that the manufacturing industry is contracting *because* of increased AI patent applications. In fact, it may even be the case, theoretically, that AI patent applications curb the severity of contraction but that it's effects are not strong enough to offset outside forces.

[^6]: Since patents have been aggregated by industry and year, the sample size also depicts the number of years for which patent counts have been recorded. Note that this does not mean that patents have been retrieved for each year (see @sec-preprocessing, p. \pageref{cleaning-missing-values}).

[^7]: Note that because the data has been detrended (see @sec-preprocessing), statements about the regression's coefficients do not reflect the actual trend of an industry. Instead, it estimates the effects in the presence of stationarity.

The opposite holds true for the information and communication industry (J), which exhibits a positive relationship between AI patent filings and gross value added per employee as well as wage adjusted labor productivity. Regarding the gross value added, the positive relationship was anticipated, and it is surpising that only the information and communication industry (J) as well as the manufacturing industry (C) exhibit significant relationships. As automation either displaces labor or aids labor productivity, one would expect the produced gross value as a ratio over the number of employees to increase with increased exposure to any type of technology. Hoewver, for the manufacturing industry (C), this relationship is negative.

To conclude, while there are indications in the results that suggest the possible exhistence of a relationship between Ai applications and the chosen economic indicators, more research is needed to verify these results. For now, the validty of the present results above should be taken with caution. There are no clear no clear patterns in the results across industries, nor across indicators. One of the few solid observations from a cross-result view is the fact that results only appear once the number of total patents filed in an industry crosses a certain threshold. This does not mean however, that indicators of industries, which are not considered in this research, should neccesarily hold significant relationships to the number of filed AI patents. Rather, it is likely that likely that a higher number of patents helps averaging out the disproportional effects between each individual patent. This will be discussed further in the \nameref{sec-limitations} (@sec-limitations). For now, the results suggest that the relationship between AI patent applications and the chosen economic indicators is not as clear as one might expect.

## Limitations {#sec-limitations}

Given the to some degree novel approach in the data collection process that this research adopted, a few limitations must be considered to assess the validty of the presented results above. First, the data quisition process. Since patents have been retrieved from the EPO API via keyword search and not - like previous research - via patent text classification (see #TODO) or occupational classification (see #TODO), the retrieved patents may not be representative of the actual number of AI patents filed. For once, keywords used to map a patent's title or abstract to its industry were only retrieved from the NACE codes' description. While kewords have been retrevied not only for the overall industry but also for each group within each divison, the keywords extracted from these descriptions are likely not fully representative for the industry as a whole. Occupations and tasks within each industry as well as characteristics of an industry are manyfold. Furthermore, a patents applicable use may not be conciled to one specific industry but rather to a type of task that occurs accross industries or occupations. These patents have likely not been retrieved and therefore lowered the data quality and size of the data set. In addition, as discussed in @sec-data-acquisition, due to language restrictions, only patents with an application number for the European Patent Office have been retrieved. While economic data retrieved from Eurostat represents aggregate country levels, patent applications filed with the EPO are not neccesarily also filed with their respective national patent office and vice versa. In other words, the patents filed with the EPO are not aggregates of the national patent offices' applications. While the total number of retrieved patent applications from the EPO is representative for the actual nuber of AI patents filed within the EU, it may also be the case that some industries tend to file patent applications generally with national patent offices rather than the EPO. Assuming that this is the case, it would mean that the distribution of retrieved patents between industries is biased. Lastly, the chosen Cooperative Patent Classification (CPC) codes may not capture all patents that are related to AI. While the CPC codes have been chosen to be as broad as possible, it is likely that some patents have been missed. As mentioned in @sec-data-sources, there are valid arguments to choose a legal definition of AI on which CPC code selection is based. However, a legal definition may fail to capture the whole spectrum of AI technologies, or capture more than what others may consider to be Artificial Intelligence. Here, the lack of a clear definition of what AI encapsulates inhibits a precise selection of AI technologies. Additionally, while a legal definition has been chosen, there is no precise mapping between the chosen definition and the CPC codes. As a result, CPC codes have been chosen as good as possible but may not be a complete set. Even with the same definition of AI, it is likely that the mapping from the definition to the CPC codes would differ from person to person as many definitions often leave room for interpretation. Regarding the CPC codes, it may also be the case that patent classification codes do not exhist for certain technologies yet, which would inhibit the precision with which patents can be retrieved.

A second limitation regards the nature and charactertistics of the patent applications themselves. More specifically, the date of patent application does not relate to the date that a patent gains economic traction. Since patent application is a time consuming process (which takes, according to the EPO between 2-5 years #TODO), the time a patent becomes economically applicable is shifted from the time a patent application is filed. This, however, is not nessecarily a severe limitation as the number of patent applications filed serve merely as a proxy for the interest and innovation in AI applications at any given time. It can be assumed, that increased inventorship in AI, as approximated by AI related patent applications, is accompanied by an increased interest in currently available AI technologies. This, of course, is merely an assumption and would need to be verified. It would be possible to shift the retrieved patent data by any given number of years, but as Eurostat's Structural Business Statistic currently only captures economic activity until 2020, most retreived patent applications would have been pushed out of the data set, making it even smaller. It would be interesting to see future research, once additional data becomes available, to reproduce a modified version of this research with retrieved patent applications' dates being shifted by the average time a patent application takes to be granted. Furthermore, as pointed out by @trajtenberg_penny_1990, the plain number of patent counts disregards the fact that patents do not carry equal economical weight. That is, the effect which a patent might have on a market or industry cannot be inferred by the presence of a patent without incorporating weights. Since this research did not aim to establish a clear link between patent applications and economic indicators, but rather used patent applications as a proxy for the interest in AI, this limitation is of lesser severity. Nevertheless, weighted patent counts may yield different results as not every patent application is, first, granted, and second, also of economic value. Lastly, the patent data retrieved from the EPO API does not contain any information on the patent's country of origin. While the EPO is an EU-wide patent office, it is likely that not all patents have been filed by EU-based companies or inventors. While some patents carry a company as the applicant's name, any inventor may file a patent with the European Patent Office, even if the inventor never intends to make economic use of the patent in the EPO's jurisdiction. Therefore, it may be the case that at least some of the patents filed with the EPO do not serve as a proxy for the interest in AI within the EU but rather outside it.

A thrid limitation is the number of data points in the final data set on which the overall analysis is build upon. While almost ten thousand patents have been retrieved from the API, only 4347 were unique in each industry, and only 1190 patents fulfilled the criteria listed in \nameref{sec-preprocessing} @sec-preprocessing. Given that Eurostat's Structural Business Statistics (SBS) does not include all industries, many retrieved patents could not be used in the analysis. Furthermore, the SBS currently carries data until 2020 which excludes the last two years in which interest in AI increased significantly. Furthermore, given the small subsets of data on which regressions were modelled, linearity was assumed. This may not accurately represent the actual relationship between the interest in, or implimentation of, AI technologies. In fact, intuitively it is likely that the relationship between AI patent applications and the chosen economic indicators are overall better represented by a polynomial regression of second order. One argument for such a relation is the counterintuitive implication that the application of linear regression involves. It is doubtful whether there can exist such a linear relationship indefinetly as it would approximate the same unit change (slope) in the dependent variable for any given unit change in the independent variable. However, economically speaking, one would expect that the marginal economic impact that additional presence of technologies has is decreasing with each additional unit (diminishing marginal returns to scale).[^8] But the opposite may also be true. As the number of AI patent applications does not describe one technology but the evolutionary path of technology, an increase in patent applications is not equal to the introduction of more of the same technology. Rather, it describes the introduction of new technology that may or may not be a substitute, complementary, or inferior product to existing technology. Therefore, as the given data is a time series, technology developed later in time has the ability to build upon (evolve from) earlier technologies. This holds true, even when considering the legal protection granted by patent rights as new novel technology is likely to spark new ideas and inventions. Hence, while the relationship between the two variables may still be assimilating the polynomial shape of order two, it may actually represent a convex shape where the marginal returns increase to scale.[^9] Here of course, the question remains whether invention is inexhaustable or not. Nevertheless, given the small size of sampes which are a result of the small time range for which data has been collected, it would be difficult to confidently assess such a relation without exposing the model to the risk of overfitting. The shape of the relationship may only appear clearly once mora data is present. In other words, once one can "zoom out" of the window that has been considered in this research, and examine more attributes of the relationship, it may be possible to assess the shape of the relationship more accurately.

[^8]: Mathematically speaking, this represents a quadratic function with a positive first order derivative and a negative second order derivative.

[^9]: In other words, a quadratic function wit positive first and second order derivatives.

Lastly, as a foruth limitation, the ommited variables. The methodology applied in this research did not include any control variables other than time, which was chosen to control for any residual trend in the detrended data. But as the statistics provided by the SBS are the result of a complex web of economic activity, which in turn is influenced by an almost incomprehensible number of factors, there is a high probability that additonal control variables would yield different results. Furthermore, it is not unlikely to think that the relationship between AI patent applications and the chosen economic indicators may have a common factor that explains both. Since research and development is a costly undertaking for many firms, it may be that other economic factors define the chosen dependent variables as well as the number of AI applications filed.

## Further research

Given the ambiguous results presented in this study, further research is needed to confirm or falsify the results presented here. In particular, future research could build upon the here presented approach and extend its methodology by including additional control variables and further improving keyword related patent extraction. Future research could also include additional data sources as proxies for the advancement in Artificial Intelligence. Perhaps, patent counts may be used not as a definite proxy for the interest or presence of technologies but as a weighting factor that accompanies additional sources of data. In addition, it would be valuable to define a clear definition of what Artificial Intelligence entails in order to build further research in this field upon a homogeneous definition that allows for cross-research comparrisson of results. Lastly, it would be interesting to see future research that builds upon the here presented approach but extends the time range for which data has been collected. This would allow for a more accurate assessment of the relationship between AI patent applications and the chosen economic indicators. Additionally, it would allow for a more accurate assessment of the shape that this relationship takes on.

# Conclusion

{{< pagebreak >}}

# References {#sec-references .unnumbered}

::: {#refs}
:::

{{< pagebreak >}}

# Appendix {#sec-appendix .unnumbered}

```{python}
#| label: tbl-nacemainkeywords
#| tbl-cap: Selected main keywords for NACE industries
#| tbl-pos: H

# show nace keywords as table
nace = dict()
for key in config["NACE_INDSUTRIES_LV_1"].keys():
  nace[key] = ", ".join(config["NACE_INDSUTRIES_LV_1"][key])
nace = pd.DataFrame.from_dict(nace, orient="index", columns=["Keywords"]).reset_index().rename(columns={"index": "NACE Section"})

nace["Keywords"] = nace["Keywords"].str.wrap(50)

Markdown(nace.to_markdown(index=False))
```

```{python}
#| label: tbl-queryexample
#| tbl-cap: Example queries posted to the OPS API
#| tbl-pos: H

import source.construct_query as cq
import json
import pandas as pd

with open("data/queries/2023-10-21_ops_search_queries.json", "r") as f:
  queries = f.read()
queries = json.loads(queries)
ls = cq.return_all_queries(queries)
df = pd.DataFrame(ls[:10], columns=["Query examples"])
display(Markdown(df.to_markdown(index=True)))
```